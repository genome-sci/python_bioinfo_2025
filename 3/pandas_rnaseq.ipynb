{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 表形式ファイルの処理\n",
    "\n",
    "## やること\n",
    "\n",
    "pandasを使ってRNA-seqデータの処理をします\n",
    "\n",
    "1. サンプルごとのカウントデータを1つのテーブルにまとめる\n",
    "2. データの読み込み\n",
    "3. カウントデータの正規化\n",
    "4. サンプル間のクラスタリング　\n",
    "5. 遺伝子のアノテーション\n",
    "    - transcript_idとgene_idの対応\n",
    "    - gene_idに対応したdescriptionの付与\n",
    "6. 発現変動遺伝子の抽出"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用データ\n",
    "\n",
    "自閉症モデルマウス細胞のRNA-seqデータセット\n",
    "\n",
    "Impaired KDM2B-mediated PRC1 recruitment to chromatin causes defective neural stem cell self-renewal and ASD/ID-like behaviors\n",
    "https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE190806\n",
    "\n",
    "BioProject\tPRJNA788503\n",
    "- SRA\tSRP350646; SRR17223720-SRR17223725\n",
    "- SRR17223720-2 Neural progenitor cells(C57BL/6J由来), **wild-type**\n",
    "- SRR17223723-5 Neural progenitor cells(C57BL/6J由来), **Kdm2b one allele mutant**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## ディレクトリとファイルの説明\n",
    "\n",
    "- `3/data/kallisto/` kallistoによるサンプルごとのカウントデータが入っている\n",
    "- `3/data/SRR_Acc_list.tsv` サンプルリスト\n",
    "- `3/data/annotation.tsv`　遺伝子アノテーション（遺伝子名とIDの対応）\n",
    "- `3/output` これから計算する結果を入れていく\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "【参考】\n",
    "- 実験医学別冊　独習Pythonバイオ情報解析\n",
    "- pandas 公式サイト　https://pandas.pydata.org\n",
    "- note.nknk.me pandas関連記事まとめ　https://note.nkmk.me/python-pandas-post-summary/\n",
    "- kallisto を用いた A. thaliana paired-end リードの転写産物の定量 https://bi.biopapyrus.jp/rnaseq/mapping/kallisto/kallisto-paired.html\n",
    "- Quasi-Mappingによって高速にRNA seqの定量を行う Kallisto https://kazumaxneo.hatenablog.com/entry/2018/07/14/180503\n",
    "- kallisto Manual http://pachterlab.github.io/kallisto/manual.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. カウントテーブルの作成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- サンプルごとのカウントデータを1つのカウントテーブルにまとめる\n",
    "\n",
    "kallistoではサンプル1個ごとのカウントデータが得られます<br>\n",
    "ほかのツールで処理するときは全部のデータをまとめたほうが扱いやすいので、kallistoのカウント結果 `abundance.tsv` をまとめてひとつのカウントテーブルを作ります<br>\n",
    "具体的には、kallistoで出力した`effective_length`と`estimate_count`でTPMを算出するため、結果を全部結合して`estimate_count`を残す、という作業をします\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "必要なモジュールをインポートします"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# versionの確認\n",
    "print(sys.version)\n",
    "print(pd.__version__)\t# pandasのバージョン確認\n",
    "print(np.__version__)\t# numpyのバージョン確認"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SRAアクセッションを1行ずつ並べた `SRR_Acc_List.txt` を読み込みます"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sralib=[i[:-1] for i in open('data/SRR_Acc_List.txt','r')]\n",
    "sralib = tuple(sralib) # 順番を変えたくないのでtupleにする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 確認\n",
    "sralib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kallistoによるカウント結果　abundance.tsvのPATHのリストを作ります<br>\n",
    "`data`フォルダの下の`kallisto`フォルダに、それぞれの結果フォルダが入っています"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kallisto_counts=[]\n",
    "for sra in sralib:\n",
    "    kallisto_counts.append('data/kallisto/' + sra + '_exp_kallisto/abundance.tsv')\n",
    "\n",
    "kallisto_counts = tuple(kallisto_counts) # 順番を変えたくないのでtupleにする"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "確認します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kallisto_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`abundance.tsv`を読み込んで、<br>\n",
    "`estimate_count`列と`tpm`列にSRAアクセッションを追加する処理を、<br>\n",
    "`read_countdata()`という関数にしておきます"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_countdata(num):\n",
    "    df = pd.read_table(kallisto_counts[num],sep='\\t')\n",
    "    newcol1 = 'est_counts_' + sralib[num]\n",
    "    newcol2 = 'tpm_' + sralib[num]\n",
    "    df.rename(columns = {'est_counts':newcol1,'tpm':newcol2}, inplace=True)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "カウントデータを読み込みます"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = read_countdata(0)\n",
    "df1 = read_countdata(1)\n",
    "df2 = read_countdata(2)\n",
    "df3 = read_countdata(3)\n",
    "df4 = read_countdata(4)\n",
    "df5 = read_countdata(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "読み込めているか確認します（いずれも同じ行数になるはず）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df0),len(df1),len(df3),len(df3),len(df4),len(df5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df0の最初の5行を表示してみます"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`target_id`列（transcript_id）と`length`列, `eff_rength`列（TPMの計算に使う）は最初のサンプルの分だけでいいので、残りの表から削除します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_count = df1.copy().drop(columns=['length','eff_length'])\n",
    "df2_count = df2.copy().drop(columns=['length','eff_length'])\n",
    "df3_count = df3.copy().drop(columns=['length','eff_length'])\n",
    "df4_count = df4.copy().drop(columns=['length','eff_length'])\n",
    "df5_count = df5.copy().drop(columns=['length','eff_length'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "target_idをkeyとして、すべてつなげます"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.merge(df0, df1_count, on = 'target_id')\n",
    "new_df = pd.merge(new_df, df2_count, on = 'target_id')\n",
    "new_df = pd.merge(new_df, df3_count, on = 'target_id')\n",
    "new_df = pd.merge(new_df, df4_count, on = 'target_id')\n",
    "new_df = pd.merge(new_df, df5_count, on = 'target_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "確認します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`est_counts`と`eff_length` だけのtable、`tpm` だけのtableを作ります<br>\n",
    "列名もSRAアクセッションのみにします"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# est_countsとeff_length\n",
    "drop_column1 = ['tpm_'+ i for i in sralib]\n",
    "drop_column1.append('length')\n",
    "rename_column1 = {'est_counts_'+ i:i for i in sralib}\n",
    "new_df_count = new_df.copy().drop(columns = drop_column1).rename(columns=rename_column1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "確認します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_count.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tpm\n",
    "drop_column2 = ['est_counts_'+ i for i in sralib]\n",
    "drop_column2.append('length')\n",
    "drop_column2.append('eff_length')\n",
    "rename_column2 = {'tpm_'+ i:i for i in sralib}\n",
    "new_df_tpm = new_df.copy().drop(columns = drop_column2).rename(columns=rename_column2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "確認します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_tpm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "タブ区切りファイルとして保存します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_count.to_csv('data/counts_kallisto.tsv', sep=\"\\t\",index=False)\n",
    "new_df_tpm.to_csv('data/tpm_kallisto.tsv', sep=\"\\t\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.データファイルの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# カウントデータをまとめたファイル ( counts_kalisto.tsv ) のパスを指定\n",
    "count_file = 'data/counts_kallisto.tsv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### カウントデータファイルについて<br>\n",
    "counts_kallisto.tsvを開くと以下のようになっています<br>\n",
    "```\n",
    "target_id\teff_length\tSRR17223720\tSRR17223721\tSRR17223722\tSRR17223723\tSRR17223724\tSRR17223725\n",
    "ENSMUST00000178537.2\t6.74193\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\n",
    "ENSMUST00000178862.2\t7.65825\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\n",
    "ENSMUST00000196221.2\t5.34639\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\n",
    "ENSMUST00000179664.2\t6.27959\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\n",
    "ENSMUST00000177564.2\t8.56364\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\n",
    "... 以下省略\n",
    "```\n",
    "1行目は列タイトルを表すヘッダー行です<br>\n",
    "2行目以降からがデータ行です。一番左の列が遺伝子idになっているのでこれをインデックスに用います"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pd.read_table()` メソッドの`index_col`オプションを指定して読み込みます<br>\n",
    "\n",
    "- index_col...インデックスとして用いる列を数字で指定します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_table(count_file, index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### データの概観\n",
    "データを概観してみましょう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# head()で列名とインデックスが正しく読み込まれているかを確認します\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'eff_length'列だけ確認\n",
    "df.eff_length.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データ件数を確認\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 列名を変更する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 列名を変更するための対応表\n",
    "names = {'SRR17223720': 'wt_1',\n",
    "         'SRR17223721': 'wt_2',\n",
    "         'SRR17223722': 'wt_3',\n",
    "         'SRR17223723': 'mutant_1',\n",
    "         'SRR17223724': 'mutant_2',\n",
    "         'SRR17223725': 'mutant_3'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`rename()` を `axis=1` を適用して使い、列名を変更します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(mapper=names, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 列名が変更されたことを確認\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "保存用に`output/`フォルダを用意し, estimate_countのみのデータを`count_raw.tsv`として保存します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count = df[['wt_1','wt_2','wt_3','mutant_1','mutant_2','mutant_3']]\n",
    "\n",
    "# estimate_countのみのデータの保存\n",
    "df_count.to_csv('output/count_raw.tsv', sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. カウントデータの正規化\n",
    "### Step1. リード数で正規化 (RPM/FPM)\n",
    "\n",
    "100万リードあたりのカウント数に揃えます<br>\n",
    "RPM = reads per million, FPM = fragments per million<br>, ほぼ同じ意味で用いられているので, 本講義では「FPM」を使います<br>\n",
    "<br>\n",
    "カウントデータをいったん別のデータフレームとしてコピーしておきます"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp = df_count.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# リード数の合計　sum()を使って計算\n",
    "sum_count = df_tmp.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 100万リードあたりに揃える\n",
    "df_tmp = 10**6 * df_tmp / sum_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "リード数の合計が100万に揃っていることを確認します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`normalize_per_million_reads()` として関数化しておきます"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_per_million_reads(df):\n",
    "    sum_count = df.sum()\n",
    "    return 10**6 * df / sum_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "カウントデータに適用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count_fpm = normalize_per_million_reads(df_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  確認\n",
    "df_count_fpm.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step2. 遺伝子長による正規化 (RPKM/FPKM)\n",
    "上で求めたFPMをさらに遺伝子長で割ってFPKMを求めます<br>\n",
    "FPKM = fragments per kilobase of exon per million reads mapped <br>\n",
    "今回用いたsingle-endの場合、<br>\n",
    "RPKM = reads per kilobase of exon per million reads mapped と呼ばれますが, <br>\n",
    "FPKM/RPKMはほぼ同じ意味で用いられています"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "各遺伝子の長さを抽出しておきます<br>\n",
    "kallistoでは実際の配列長（abundance.tsvの`length`列）ではなく、`eff_length`列でTPMを計算しているので、<br>\n",
    "本講義でも`eff_length`列の値を用います<br>\n",
    "\n",
    "\n",
    "【参考】　次世代シーケンサーデータの解析手法 第15回 RNA-seq 解析(その3)<br>\n",
    "DOI: https://doi.org/10.4109/jslab.31.25\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_length = df['eff_length']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本でいくつか計算方法を紹介していますが、今日はデータフレームを転置してから計算する方法でやってみます"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# テスト用にFPMをコピー\n",
    "df_tmp = df_count_fpm.copy()\n",
    "\n",
    "# df_tmpを転置してFPMを遺伝子長で割り, 1000をかける\n",
    "df_tmp = df_tmp.T / gene_length * 10**3\n",
    "\n",
    "# 戻す（もう一度転置する）\n",
    "df_tmp = df_tmp.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これを `normalize_per_kilobase()` として関数化しておきます"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_per_kilobase(df, gene_length):\n",
    "    df_tmp = df.copy()\n",
    "    df_tmp = (df.T * 10**3 / gene_length).T\n",
    "    return df_tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "先ほど計算したFPMの結果に適用します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count_fpkm = normalize_per_kilobase(df_count_fpm, gene_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存する\n",
    "df_count_fpkm.to_csv('output/count_fpkm.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step3. TPM 正規化\n",
    "TPM = transcripts per million (transcripts per kilobase million)<br> \n",
    "TPM の説明については以下のページが詳しいです https://bi.biopapyrus.jp/ <br> \n",
    "\n",
    "FPKM/RPKM のときとは逆に、長さ1,000bpあたりのリード数を求めてから、総リード数を100万に揃えます"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# テスト用にカウントデータをコピー\n",
    "df_tmp = df_count.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp = normalize_per_kilobase(df_tmp, gene_length) #長さ1,000bpあたりのリード数\n",
    "df_tmp = normalize_per_million_reads(df_tmp) #総リード数を100万に揃える"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RPKM/FPKMと違い、合計が100万となっています"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`normalize_tpm()` として関数化しておきます"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_tpm(df, gene_length):\n",
    "    df_tmp = df.copy()\n",
    "    df_tmp = normalize_per_kilobase(df_tmp, gene_length)\n",
    "    df_tmp = normalize_per_million_reads(df_tmp)\n",
    "    return df_tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "カウントデータに適用します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count_tpm = normalize_tpm(df_count, gene_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 確認\n",
    "df_count_tpm.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存\n",
    "df_count_tpm.to_csv('output/count_tpm.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. TPM正規化したデータのクラスタリング\n",
    "matplotlib と scipy の必要モジュールをインポートします"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 転置\n",
    "tpm_t = df_count_tpm.T\n",
    "\n",
    "# 確認\n",
    "tpm_t.iloc[:,0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# クラスタリング\n",
    "linkage_result = linkage(tpm_t, method='average', metric='correlation')\n",
    "\n",
    "# 結果の可視化\n",
    "plt.figure(num=None, figsize = (8,4), facecolor='w', edgecolor='k')\n",
    "dendrogram(linkage_result,labels = list(tpm_t.index) )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCAもやってみましょう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA()\n",
    "pca.fit(tpm_t)\n",
    "\n",
    "# データを主成分空間に写像\n",
    "pca_row = pca.transform(tpm_t)\n",
    "\n",
    "# 寄与率を求める\n",
    "pca_col = [\"PC{}\".format(x + 1) for x in range(len(tpm_t.index))]\n",
    "df_con_ratio = pd.DataFrame([pca.explained_variance_ratio_], columns = pca_col)\n",
    "print(df_con_ratio.head())\n",
    "\n",
    "# PC1とPC2でplot\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.scatter(pca_row[:, 0], pca_row[:, 1], alpha=0.8, c=(1,1,1,2,2,2))\n",
    "plt.grid()\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "annotations = tpm_t.index\n",
    "for i, label in enumerate(annotations):\n",
    "    plt.annotate(label, (pca_row[i, 0], pca_row[i, 1]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 遺伝子のアノテーション"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step1. アノテーションファイルを読み込む\n",
    "\n",
    "アノテーションデータ `annotation.tsv` はGRCm39のGFFファイル( `Mus_musculus.GRCm39.108.gff3` ) から必要な情報を抽出して作成しました<br>\n",
    "`annotation.tsv`を開くと以下のようになっています<br>\n",
    "\n",
    "```\n",
    "ENSMUST00000070533.5\tENSMUSG00000051951\tXkr4\tX-linked Kx blood group related 4 [Source:MGI Symbol;Acc:MGI:3528744]\n",
    "ENSMUST00000208660.2\tENSMUSG00000025900\tRp1\tretinitis pigmentosa 1 (human) [Source:MGI Symbol;Acc:MGI:1341105]\n",
    "ENSMUST00000027032.6\tENSMUSG00000025900\tRp1\tretinitis pigmentosa 1 (human) [Source:MGI Symbol;Acc:MGI:1341105]\n",
    "ENSMUST00000027035.10\tENSMUSG00000025902\tSox17\tSRY (sex determining region Y)-box 17 [Source:MGI Symbol;Acc:MGI:107543]\n",
    "ENSMUST00000195555.2\tENSMUSG00000025902\tSox17\tSRY (sex determining region Y)-box 17 [Source:MGI Symbol;Acc:MGI:107543]\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# アノテーションデータ(transcript_id, gene_id, descriptionを紐づけたファイル ( annotation.tsv ) のパスを指定\n",
    "annotation_file = 'data/annotation.tsv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataFrame名を `annotations` として、 <br>\n",
    "ヘッダー（列名）は `names=['transcript_id', 'gene_id', 'gene_name', 'description']`として読み込みます"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = pd.read_table(annotation_file, names=['transcript_id', 'gene_id', 'gene_name', 'description'])\n",
    "print(annotations.shape)\n",
    "annotations.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step2. アノテーションデータとカウントデータを連結\n",
    "2つのDataFrame `df` と `annotations` を連結します<br>\n",
    "`annotation` には mRNA のデータしか含まれていないので、rRNA などのデータはこの時点で除かれます<br>\n",
    "ただし、`gene_name`列の値が `mt-` で始まるミトコンドリア遺伝子が含まれています"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_product = df.copy()\n",
    "df_with_product['transcript_id'] = df_with_product.index\n",
    "df_with_product.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pandasの`merge()`を使います"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_product = pd.merge(df_with_product, annotations, on='transcript_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transcript_id列をindexにする\n",
    "df_with_product.set_index('transcript_id', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "アノテーション付きカウントデータを`count_preprocessed.tsv`として保存します<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# アノテーション付きデータの保存\n",
    "df_with_product.to_csv('output/count_preprocessed.tsv', sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TPMデータにもアノテーション付与"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tpm_with_product = df_count_tpm.copy()\n",
    "df_tpm_with_product['transcript_id'] = df_tpm_with_product.index\n",
    "df_tpm_with_product = pd.merge(df_tpm_with_product, annotations, on='transcript_id', how='inner')\n",
    "df_tpm_with_product.set_index('transcript_id', inplace=True)\n",
    "\n",
    "df_tpm_with_product.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# アノテーション付きデータの保存\n",
    "df_tpm_with_product.to_csv('output/tpm_with_product.tsv', sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 発現変動遺伝子を抽出する\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TPM正規化データを用います<br>\n",
    "wild typeの平均を求めます"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count_tpm['wt'] = (df_count_tpm['wt_1'] + df_count_tpm['wt_2'] + df_count_tpm['wt_3']) / 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mutantの平均を求めます"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count_tpm['mutant'] = (df_count_tpm['mutant_1'] + df_count_tpm['mutant_2'] + df_count_tpm['mutant_3']) / 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "発現変動をlog2 fold として求めます<br>\n",
    "0 での除算を防ぐため、分母に微小な値を加えています<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count_tpm['log2fold'] = df_count_tpm['mutant'] / (df_count_tpm['wt'] + 10**-6)\n",
    "df_count_tpm['log2fold'] = df_count_tpm['log2fold'].apply(np.log2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "必要部分のみ抜き出し、遺伝子アノテーション（タンパク質名）と結合します<br>\n",
    "`df_count_tpm` から'wt', 'mutant', 'log2fold'の列を抜き出し`diff_ex`とします"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_ex = df_count_tpm.copy()\n",
    "diff_ex = diff_ex[['wt', 'mutant', 'log2fold']]\n",
    "diff_ex ['transcript_id']= diff_ex.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`annotations`（遺伝子アノテーションのテーブル）と結合します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_ex = pd.merge(diff_ex, annotations, on = 'transcript_id', how = 'right')\n",
    "diff_ex.set_index('transcript_id', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_ex.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "カウント数が0であるデータを除きます"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_ex = diff_ex[diff_ex['wt'] > 0]\n",
    "diff_ex = diff_ex[diff_ex['mutant'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データ数の確認\n",
    "diff_ex.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 概観\n",
    "diff_ex.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`diff_ex.sort_values()`を使い`log2fold`の降順に並びかえます"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_ex = diff_ex.sort_values(by = 'log2fold',ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "発現変動遺伝子の上位を表示してみましょう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mutant > wt の上位5番目まで表示\n",
    "diff_ex.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wt > mutant の上位5番目まで表示\n",
    "diff_ex.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "おつかれさまでした！"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pags2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
